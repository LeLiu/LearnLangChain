{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用LangChain调用LLM\n",
    "\n",
    "## 安装LangChain\n",
    "\n",
    "使用以下命令安装LangChain。由于使用DeepSeek模型，因此要同时安装`langchain-deepseek`。\n",
    "\n",
    "```python\n",
    "%pip install langchain langchain-deepseek\n",
    "```\n",
    "\n",
    "> ⚠️注意：\n",
    "> 如果使用的是虚拟环境(例如Conda或者virtualenv)，应该使用魔法命令`%pip install`，而非shell命令`!pip install`，因为前者会将软件\n",
    "> 包安装至当前环境，而后者会将软件包安装至默认环境。\n",
    "\n",
    "使用DeepSeek时，要设置环境变量`DEEPSEEK_API_KEY`。使用其它的大模型时，也要在环境变量中设置好对应的API_KEY，比如使用OpenAI的模型时\n",
    "要设置`OPENAI_API_KEY`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用`init_chat_model`来创建LLM\n",
    "\n",
    "一种方法是调用`init_chat_model`函数来根据传入的参数初始化对应的模型类。然后执行模型的`invoke`方法来进行大模型调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "model = init_chat_model(model='deepseek-chat', model_provider='deepseek')\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"将输入的文字翻译成英语。\"),\n",
    "    HumanMessage(\"你好。\"),\n",
    "]\n",
    "\n",
    "message = model.invoke(messages)\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Stream进行输出\n",
    "\n",
    "如果要流式的输出模型的返回内容，需要循环调用`stream`方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Hello|.||"
     ]
    }
   ],
   "source": [
    "for chunk in model.stream(messages):\n",
    "    print(chunk.content, end='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 直接构造LLM类\n",
    "\n",
    "另一种方式是直接构造一个模型对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n"
     ]
    }
   ],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [SystemMessage('请将输入的文字翻译成英文。'),\n",
    "            HumanMessage('您好。')]\n",
    "\n",
    "ds_model = ChatDeepSeek(model='deepseek-chat')\n",
    "message = ds_model.invoke(messages)\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用OpenAI格式输入\n",
    "\n",
    "除了通过Message列表的形式作为输入，还可以以OpenAI的字典格式来作为输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n"
     ]
    }
   ],
   "source": [
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': '请将输入的文字翻译成英文。'},\n",
    "    {'role': 'user', 'content': '您好。'},\n",
    "    ]\n",
    "\n",
    "ds_model = ChatDeepSeek(model='deepseek-chat')\n",
    "message = ds_model.invoke(messages)\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 使用提示词模板\n",
    "\n",
    " 实际应用过程中，提示词往往都不是固定的，而是会根据具体的情况变化。langchain提供了`ChatPromptTemplate`来应对这种情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='こんにちは', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 11, 'total_tokens': 16, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}, 'prompt_cache_hit_tokens': 0, 'prompt_cache_miss_tokens': 11}, 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_3d5141a69a_prod0225', 'id': 'cb2d1824-eb33-455a-a7ec-fbe3ab0ace20', 'finish_reason': 'stop', 'logprobs': None}, id='run-0b0f04f3-dbe0-4dda-8cd3-5768dc276701-0', usage_metadata={'input_tokens': 11, 'output_tokens': 5, 'total_tokens': 16, 'input_token_details': {'cache_read': 0}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', '请将输入的文字翻译成{language}'),\n",
    "        ('user', '{text}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = prompt_template.invoke({'language': '日语', 'text': '您好'})\n",
    "\n",
    "ds_model = ChatDeepSeek(model='deepseek-chat')\n",
    "ds_model.invoke(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
